{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tzifpavdqyqewux94undas",
    "execution_id": "830e5068-e231-4b20-9030-53452dcafbb9"
   },
   "source": [
    "Colab related:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "cellId": "twa2b910vetdy3imvw9ke"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !cp -r \"/content/drive/MyDrive/Colab Notebooks/Diploma/handle_amazon/amazon_en\" .\n",
    "# !cp -r \"/content/drive/MyDrive/Colab Notebooks/Diploma/handle_amazon/amazon_fr\" .\n",
    "# !cp -r \"/content/drive/MyDrive/Colab Notebooks/Diploma/handle_amazon/amazon_de\" .\n",
    "# !cp -r \"/content/drive/MyDrive/Colab Notebooks/Diploma/handle_amazon/amazon_es\" .\n",
    "\n",
    "# !pip install transformers datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "v831r2aygog3x9slcprgqp",
    "execution_id": "dc737fe0-a23f-43f2-ac8c-939d6aea6935"
   },
   "source": [
    "DS related:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "cellId": "6l4nyns1vqw0te31t4kcxiq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# %pip install seaborn\n",
    "# %pip install transformers datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rxhcw6use2ebj2mdo2000h",
    "execution_id": "5afa3752-28fe-4f45-9cb0-fe436da73131"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "cellId": "fxdwij12bpolkqq4qile0p"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def nice_df(df, axis=None, reverse=False, **kwargs):\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True, reverse=reverse)\n",
    "    return df.style.background_gradient(cmap=cm, axis=axis, **kwargs)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "feqye9ul8wpeaqq4kq58fh",
    "execution_id": "f36f8a0a-052e-4620-861a-7d7c58bed833"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "cellId": "xtgnwed3pic2eib69a5kdo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# !unzip handle_amazon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "cellId": "u48gfhuc15rxodqn8e2oh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from datasets import concatenate_datasets, load_from_disk\n",
    "\n",
    "BS = 32\n",
    "lang_list = ['en', 'fr', 'de', 'es']\n",
    "split_list = ['train', 'validation', 'test']\n",
    "\n",
    "\n",
    "# data = {\n",
    "#     lang: load_from_disk(f'handle_amazon/amazon_{lang}')\n",
    "#     for lang in lang_list\n",
    "# }\n",
    "\n",
    "tr_data = {\n",
    "    lang: load_from_disk(f'handle_amazon/amazon_ok_tr_{lang}')\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n",
    "dataloader = {\n",
    "    lang: {\n",
    "        split: DataLoader(tr_data[lang][split], batch_size=BS, shuffle=(split == 'train'))\n",
    "        for split in split_list\n",
    "    }\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "l7nvel55c7kc331er7atci",
    "execution_id": "f7e5ce33-d8a0-42fd-8f5d-12ad7218ba12"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "cellId": "dvhg8jfj2rmlm4lcit0ekd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3267,  0.0176,  0.1214,  ...,  0.0836, -0.0200, -0.1360],\n",
      "        [ 0.1976,  0.1497,  0.1829,  ...,  0.0148,  0.0260, -0.0101],\n",
      "        [ 0.1492,  0.0464,  0.1645,  ..., -0.0861, -0.0884,  0.0062],\n",
      "        ...,\n",
      "        [ 0.1911,  0.1054, -0.0288,  ..., -0.0056,  0.0567, -0.1306],\n",
      "        [ 0.1369,  0.0744,  0.1030,  ...,  0.0234, -0.1261, -0.0686],\n",
      "        [ 0.1460,  0.2451,  0.0183,  ...,  0.1160, -0.0157, -0.1809]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0517,  0.1344],\n",
      "        [-0.0739,  0.1222],\n",
      "        [-0.1158,  0.1851],\n",
      "        [-0.0793,  0.0786],\n",
      "        [-0.0583,  0.1682],\n",
      "        [-0.0760,  0.1323],\n",
      "        [-0.1093,  0.1419],\n",
      "        [-0.0584,  0.1381],\n",
      "        [-0.0957,  0.1648],\n",
      "        [-0.1241,  0.1488],\n",
      "        [-0.0860,  0.1974],\n",
      "        [-0.0562,  0.1290],\n",
      "        [-0.0872,  0.1571],\n",
      "        [-0.1066,  0.1114],\n",
      "        [-0.1126,  0.1718],\n",
      "        [-0.1448,  0.1664],\n",
      "        [-0.1365,  0.1943],\n",
      "        [ 0.0068,  0.1577],\n",
      "        [-0.0718,  0.1091],\n",
      "        [-0.1472,  0.2074],\n",
      "        [-0.0835,  0.1358],\n",
      "        [-0.0974,  0.1142],\n",
      "        [-0.0614,  0.1456],\n",
      "        [-0.0512,  0.1214],\n",
      "        [-0.0595,  0.1469],\n",
      "        [-0.0943,  0.1749],\n",
      "        [-0.1159,  0.1011],\n",
      "        [-0.0751,  0.1290],\n",
      "        [-0.1062,  0.1710],\n",
      "        [-0.1409,  0.2003],\n",
      "        [-0.0994,  0.1383],\n",
      "        [-0.1051,  0.1696]], device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "models = dict()\n",
    "for lang in lang_list:\n",
    "    models[lang] = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id, output_hidden_states=True)\n",
    "    models[lang].to(device)\n",
    "    for param in models[lang].base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader['en']['test']:\n",
    "        i_d = batch[\"input_ids\"].to(device)\n",
    "        a_m = batch[\"attention_mask\"].to(device)\n",
    "        batch_hs = models['en'](\n",
    "                input_ids=i_d,\n",
    "                attention_mask=a_m,\n",
    "            ).hidden_states[-1].mean(dim=1)    \n",
    "        print(batch_hs)\n",
    "\n",
    "        logits = models['en'](\n",
    "                input_ids=i_d,\n",
    "                attention_mask=a_m,\n",
    "            ).logits    \n",
    "        print(logits)\n",
    "\n",
    "        print(torch.argmax(\n",
    "            models['en'](\n",
    "                input_ids=i_d,\n",
    "                attention_mask=a_m,\n",
    "            ).logits,\n",
    "            axis=-1\n",
    "        ))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "cellId": "65g6honk6dgx9xmovkxthm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "from transformers import pipeline\n",
    "\n",
    "translators = {\n",
    "    lang: pipeline(\"translation\", model=f\"Helsinki-NLP/opus-mt-{lang}-en\", max_length=6)\n",
    "    for lang in ['fr', 'de', 'es']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "cellId": "7vpq7lbwszmn23fmmz7x"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def get_top_words(lang_data, K=1000):\n",
    "    # Extract the 'review_body' column from the dataset\n",
    "    reviews = lang_data['train']['review_body']\n",
    "\n",
    "    # Concatenate all the reviews into a single string\n",
    "    all_reviews = ' '.join(reviews)\n",
    "    all_reviews = all_reviews.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))\n",
    "\n",
    "    # Tokenize the concatenated string into individual tokens\n",
    "    tokens = all_reviews.split()\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # Calculate the frequency of each token\n",
    "    token_freq = Counter(tokens)\n",
    "\n",
    "    # Sort the tokens based on their frequency in descending order\n",
    "    sorted_tokens = sorted(token_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the top 1000 most frequent tokens\n",
    "    top_K_tokens = [token for token, freq in sorted_tokens[:K]]\n",
    "    return top_K_tokens\n",
    "\n",
    "def get_translation_pairs(lang, K=1000):\n",
    "    top_words = get_top_words(tr_data[lang], K=K)\n",
    "    top_translated = [x['translation_text'] for x in translators[lang](top_words)]\n",
    "\n",
    "    normalize = lambda x: x.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))).lower().strip()\n",
    "    normalize2 = lambda x: x if len(x) > 0 else 'XXX'\n",
    "    top_translated = [normalize(x) for x in top_translated]\n",
    "    top_translated = [normalize2(x) for x in top_translated]\n",
    "\n",
    "    pairs = list(zip(top_words, top_translated))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def warm_up_model(model, tokenizer, lang, K):\n",
    "    pairs = get_translation_pairs(lang, K)\n",
    "\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    word_embeddings = model.base_model.embeddings.word_embeddings.weight\n",
    "\n",
    "    new_embed_list = list()\n",
    "    for word, translation in pairs[::-1]:\n",
    "        list_of_tr = [word.lower() for word in translation.split()]\n",
    "        ids = [tokenizer.convert_tokens_to_ids(tr) for tr in list_of_tr]\n",
    "#         print(word, translation, ids, sep=' : ')\n",
    "        embeds = [word_embeddings[id] for id in ids]\n",
    "        if len(embeds) == 0:\n",
    "            print(word, translation)\n",
    "        new_embed = torch.zeros_like(embeds[0])\n",
    "        for embed in embeds:\n",
    "            new_embed += embed\n",
    "        new_embed /= len(embeds)\n",
    "        new_embed_list.append((word, new_embed))\n",
    "\n",
    "    for word, new_embed in new_embed_list:\n",
    "        token_id = tokenizer.convert_tokens_to_ids(word)\n",
    "        word_embeddings[token_id] = new_embed\n",
    "\n",
    "    for param in model.base_model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "cellId": "cbuc038n22pojqff4skwdg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 7 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 7 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 7 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 7 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 6 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 7 is bigger than 0.9 * max_length: 6. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "for lang in ['fr', 'es', 'de']:\n",
    "    warm_up_model(models[lang], tokenizer, lang, 5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "cellId": "u8uvi7fdjc987q12pzcmxt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "for lang in lang_list:\n",
    "    for param in models[lang].base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "cellId": "iqyx4dgc9ssvmbltew77l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n",
      "en is ok\n",
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n",
      "fr is ok\n",
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n",
      "de is ok\n",
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n",
      "es is ok\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "for lang in lang_list:\n",
    "    for name, param in models[lang].named_parameters():\n",
    "        if 'clas' in name:\n",
    "            print(name, param.shape, param.requires_grad)\n",
    "        else:\n",
    "#             print(name)\n",
    "            assert not param.requires_grad\n",
    "    print(f'{lang} is ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "2tx9ggh41g2u7nnvdtxwyq",
    "execution_id": "1fe0c94e-5d0d-4ce7-8ebf-a6d2eddc350a"
   },
   "source": [
    "## Eval and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "cellId": "avhaedat3cbxjqz4secpwh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def eval(model, dls, lang, test_split):\n",
    "    # put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # get needful data slice\n",
    "    dl_to_test = dls[lang][test_split]\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl_to_test):\n",
    "            # move batch to device\n",
    "            input_ids = batch['input_ids'].to(model.device)\n",
    "            attention_mask = batch['attention_mask'].to(model.device)\n",
    "            labels = batch['bin_label'].to(model.device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # calculate loss and accuracy\n",
    "            preds = logits.argmax(dim=1)\n",
    "            test_acc += (preds == labels).sum().item()\n",
    "\n",
    "    test_acc /= BS * len(dl_to_test)\n",
    "    print(f'\\teval {lang}: {test_acc}')\n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "cellId": "84x8yyc3nemue9h5ppg4ob"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def train(model, dls, lang, train_split, validation_split, num_epochs=2, device='mps'):\n",
    "    # put model on mps device\n",
    "    model.to(device)\n",
    "    \n",
    "    # get needful data slice\n",
    "    dl_to_train = dls[lang][train_split]\n",
    "    dl_to_valid = dls[lang][validation_split]\n",
    "\n",
    "    # define our optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train loop\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for batch in tqdm(dl_to_train):\n",
    "            # move batch to device\n",
    "            input_ids = batch['input_ids'].to(model.device)\n",
    "            attention_mask = batch['attention_mask'].to(model.device)\n",
    "            labels = batch['bin_label'].to(model.device)\n",
    "\n",
    "            # zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # calculate loss and accuracy\n",
    "            loss = loss_fn(logits, labels)\n",
    "            train_loss += loss.item()\n",
    "            preds = logits.argmax(dim=1)\n",
    "            train_acc += (preds == labels).sum().item()\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "\n",
    "        train_acc /= BS * len(dl_to_train)\n",
    "        valid_acc = eval(model, dls, lang, validation_split)\n",
    "        print(f'train {lang}: {train_acc} (val {valid_acc})')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "yrd3fhstfjgijz0jbsxaw9",
    "execution_id": "54f4b1c5-b973-440d-a8b1-b70d281935f5"
   },
   "source": [
    "## All Lang Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "cellId": "8c7swb5tp9bgz938gqeq6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\teval en: 0.8735\n",
      "train en: 0.867075 (val 0.8735)\n",
      "\teval en: 0.87425\n",
      "train en: 0.86969375 (val 0.87425)\n",
      "\teval fr: 0.795\n",
      "train fr: 0.78015 (val 0.795)\n",
      "\teval fr: 0.796\n",
      "train fr: 0.78205 (val 0.796)\n",
      "\teval de: 0.74725\n",
      "train de: 0.72305 (val 0.74725)\n",
      "\teval de: 0.751\n",
      "train de: 0.72688125 (val 0.751)\n",
      "\teval es: 0.7905\n",
      "train es: 0.77488125 (val 0.7905)\n",
      "\teval es: 0.7915\n",
      "train es: 0.77685625 (val 0.7915)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:18<00:00,  5.11it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.40it/s]\n",
      "100%|██████████| 5000/5000 [16:19<00:00,  5.11it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for lang in lang_list:\n",
    "    train(models[lang], dataloader, lang, 'train', 'validation', num_epochs=2, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "cellId": "c2a6zdgk8iqi1qw2gd1mkj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "# for lang in lang_list:\n",
    "#     if lang != 'en':\n",
    "#         train(models[lang], dataloader, lang, 'train', 'validation', lang=lang, num_epochs=3, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "cellId": "mxlcro8et1n13c8ocxff2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:23<00:00,  5.39it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.39it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.39it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\teval en: 0.87675\n",
      "\teval fr: 0.79475\n",
      "\teval de: 0.7565\n",
      "\teval es: 0.79475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_2a3ea654_025a_11ee_8de3_d00d1053ea47row0_col0 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_2a3ea654_025a_11ee_8de3_d00d1053ea47row1_col0 {\n",
       "            background-color:  #a0cea0;\n",
       "            color:  #000000;\n",
       "        }    #T_2a3ea654_025a_11ee_8de3_d00d1053ea47row2_col0 {\n",
       "            background-color:  #ebf3eb;\n",
       "            color:  #000000;\n",
       "        }    #T_2a3ea654_025a_11ee_8de3_d00d1053ea47row3_col0 {\n",
       "            background-color:  #a0cea0;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >finetune</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47level0_row0\" class=\"row_heading level0 row0\" >en</th>\n",
       "                        <td id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47row0_col0\" class=\"data row0 col0\" >0.87675</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47level0_row1\" class=\"row_heading level0 row1\" >fr</th>\n",
       "                        <td id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47row1_col0\" class=\"data row1 col0\" >0.79475</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47level0_row2\" class=\"row_heading level0 row2\" >de</th>\n",
       "                        <td id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47row2_col0\" class=\"data row2 col0\" >0.7565</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47level0_row3\" class=\"row_heading level0 row3\" >es</th>\n",
       "                        <td id=\"T_2a3ea654_025a_11ee_8de3_d00d1053ea47row3_col0\" class=\"data row3 col0\" >0.79475</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f8d8870a9d0>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "eval_res = pd.DataFrame(data = np.zeros((4, 1)), columns = ['finetune'], index=lang_list)\n",
    "\n",
    "for lang in lang_list:\n",
    "    test_res = eval(models[lang], dataloader, lang, 'test')\n",
    "    eval_res.at[lang, 'finetune'] = test_res\n",
    "\n",
    "nice_df(eval_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "cellId": "ayqg6di0kxpi3yxynhtkr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "for lang in lang_list:\n",
    "    models[lang].save_pretrained(f'models/ft_ht_{lang}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "cellId": "tr8pod1puznnh3sukqor"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "125\n",
      "125\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for lang in lang_list:\n",
    "    print(len(dataloader[lang]['train']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mziqfsye3qfxlfhsvr9zhs"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "f9ef1147-8eb1-4fcf-a151-7a5f10df7219",
  "notebookPath": "finetune_hot_start.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
