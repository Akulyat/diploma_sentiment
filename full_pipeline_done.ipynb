{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eb4d97f",
   "metadata": {
    "cellId": "49exldv2jia8popw3nfuk3",
    "execution_id": "914fd528-1eb6-4709-9509-7419952c7300"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51812956",
   "metadata": {
    "cellId": "m4cs2ge8ncox38w8qll2rn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def nice_df(df, axis=None, reverse=False, **kwargs):\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True, reverse=reverse)\n",
    "    return df.style.background_gradient(cmap=cm, axis=axis, **kwargs)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d4826",
   "metadata": {
    "cellId": "smtwz30ludn1htqomaf3r",
    "execution_id": "49ea8e17-9a9c-4cc7-85a6-8caee37751f0"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11fc8a2e",
   "metadata": {
    "cellId": "j7vpiwzslpt538zzp9kh8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenization(examples: np.ndarray):\n",
    "    return tokenizer(examples.tolist(), truncation=True, padding=True, pad_to_multiple_of=40, max_length=40, return_tensors='pt')\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.en_id = data[\"en_id\"]\n",
    "        self.en_am = data[\"en_am\"]\n",
    "        self.fr_id = data[\"fr_id\"]\n",
    "        self.fr_am = data[\"fr_am\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.en_id)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"en_id\": self.en_id[index], \n",
    "            \"en_am\": self.en_am[index],\n",
    "            \"fr_id\": self.fr_id[index],\n",
    "            \"fr_am\": self.fr_am[index],\n",
    "        }\n",
    "\n",
    "def get_dataloaer(lang, batch_size = 32):\n",
    "    done = 100 * 1000\n",
    "    file_path = f'saved_tr_lists/list_{lang}_{done}.pkl'\n",
    "\n",
    "    with open(file_path, 'rb') as file:\n",
    "        tr_pairs = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "    np_pairs = np.array(tr_pairs)\n",
    "    fr_torch  = tokenization(np_pairs[:, 0])\n",
    "    en_torch = tokenization(np_pairs[:, 1])\n",
    "\n",
    "    data = {\n",
    "        \"en_id\": en_torch['input_ids'],\n",
    "        \"en_am\": en_torch['attention_mask'],\n",
    "        \"fr_id\": fr_torch['input_ids'],\n",
    "        \"fr_am\": fr_torch['attention_mask'],\n",
    "    }\n",
    "\n",
    "    dataset = CustomDataset(data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "lang_list_tr = ['fr', 'de', 'es']\n",
    "dataloaders_tr = {\n",
    "    lang: get_dataloaer(lang)\n",
    "    for lang in lang_list_tr\n",
    "}\n",
    "\n",
    "for lang in lang_list_tr:\n",
    "    sum = 0\n",
    "    # Iterate over the dataloader\n",
    "    for batch in dataloaders_tr[lang]:\n",
    "        en_id = batch[\"en_id\"]\n",
    "        en_am = batch[\"en_am\"]\n",
    "        fr_id = batch[\"fr_id\"]\n",
    "        fr_am = batch[\"fr_am\"]\n",
    "\n",
    "        # Use the batched data for further processing\n",
    "        if False:\n",
    "            print(\"Input IDs:\", en_id.shape)\n",
    "            print(\"Attention Mask:\", en_am.shape)\n",
    "            print(\"Input IDs:\", fr_id.shape)\n",
    "            print(\"Attention Mask:\", fr_am.shape)\n",
    "            print(\"Input IDs:\", en_id[:2, :5])\n",
    "            print(\"Input IDs:\", fr_id[:2, :5])\n",
    "            break\n",
    "\n",
    "        sum += en_id.shape[0]\n",
    "\n",
    "    print(sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae5c430c",
   "metadata": {
    "cellId": "qmhy0a2bf0qt8igssvfe9e"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from datasets import concatenate_datasets, load_from_disk\n",
    "\n",
    "BS = 32\n",
    "lang_list = ['en', 'fr', 'de', 'es']\n",
    "split_list = ['train', 'validation', 'test']\n",
    "\n",
    "\n",
    "# data = {\n",
    "#     lang: load_from_disk(f'handle_amazon/amazon_{lang}')\n",
    "#     for lang in lang_list\n",
    "# }\n",
    "\n",
    "tr_data = {\n",
    "    lang: load_from_disk(f'handle_amazon/amazon_ok_tr_{lang}')\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n",
    "dataloader = {\n",
    "    lang: {\n",
    "        split: DataLoader(tr_data[lang][split], batch_size=BS, shuffle=(split == 'train'))\n",
    "        for split in split_list\n",
    "    }\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f8e3d",
   "metadata": {
    "cellId": "ofdpzbupj1gkbgyk2lk3xh",
    "execution_id": "537c320e-1e55-4cfd-b957-7dbf601511e8"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "57438c6f",
   "metadata": {
    "cellId": "7npe6man25rkud4t86s62"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "models = dict()\n",
    "for lang in lang_list:\n",
    "    models[lang] = DistilBertForSequenceClassification.from_pretrained(f'models/ft_ht_{lang}')\n",
    "    models[lang].to(device)\n",
    "\n",
    "for lang in lang_list:\n",
    "    for param in models[lang].base_model.parameters():\n",
    "        param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "27a50a1c",
   "metadata": {
    "cellId": "glht1wbvouoki3bd9rula"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n",
      "en is ok\n",
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n",
      "fr is ok\n",
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n",
      "de is ok\n",
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n",
      "es is ok\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "for lang in lang_list:\n",
    "    for name, param in models[lang].named_parameters():\n",
    "        if 'clas' in name:\n",
    "            print(name, param.shape, param.requires_grad)\n",
    "        assert param.requires_grad\n",
    "    print(f'{lang} is ok')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3055d563",
   "metadata": {
    "cellId": "z12idlnuq7brlv1i1h8ca",
    "execution_id": "13b75d53-254f-4b68-9728-089470aa5804"
   },
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec102cfc",
   "metadata": {
    "cellId": "ssfo69tu5o2zdjv64pz5j"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def eval(model, dls, lang, test_split):\n",
    "    # put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # get needful data slice\n",
    "    dl_to_test = dls[lang][test_split]\n",
    "    \n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dl_to_test):\n",
    "            # move batch to device\n",
    "            input_ids = batch['input_ids'].to(model.device)\n",
    "            attention_mask = batch['attention_mask'].to(model.device)\n",
    "            labels = batch['bin_label'].to(model.device)\n",
    "\n",
    "            # forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # calculate loss and accuracy\n",
    "            preds = logits.argmax(dim=1)\n",
    "            test_acc += (preds == labels).sum().item()\n",
    "\n",
    "    test_acc /= BS * len(dl_to_test)\n",
    "    print(f'\\teval {lang}: {test_acc}')\n",
    "    return test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03d4434f",
   "metadata": {
    "cellId": "h5dq727rrsf8i8ouxohg2e"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "import random\n",
    "def epoch_sentiment(model, dls, dl, lang, validation_split, optimizer, sample_size=-1, debug=False):\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    if debug:\n",
    "        if sample_size == -1:\n",
    "            sample_size = 100\n",
    "        else:\n",
    "            sample_size = sample_size // 10\n",
    "    if sample_size != -1:\n",
    "        sampled_batches = random.sample(list(dl), sample_size)\n",
    "    else:\n",
    "        sampled_batches = dl\n",
    "\n",
    "    batch_num = 0\n",
    "    for batch in tqdm(sampled_batches):\n",
    "        # move batch to device\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['bin_label'].to(model.device)\n",
    "\n",
    "        # zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # calculate loss and accuracy\n",
    "        loss = loss_fn(logits, labels)\n",
    "        train_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        train_acc += (preds == labels).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_num += 1\n",
    "        if batch_num > 200 and debug:\n",
    "            break\n",
    "\n",
    "    train_acc /= BS * batch_num\n",
    "    valid_acc = eval(model, dls, lang, validation_split)\n",
    "    print(f'train {lang}: {train_acc} (val {valid_acc})')\n",
    "    return (train_acc, valid_acc)\n",
    "\n",
    "def epoch_translation(model, dls, dl, lang, validation_split, optimizer, debug=False):\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    train_loss = 0\n",
    "    \n",
    "\n",
    "    batch_num = 0\n",
    "    for batch in tqdm(dl):\n",
    "        # move batch to device\n",
    "        en_id = batch[\"en_id\"].to(model.device)\n",
    "        en_am = batch[\"en_am\"].to(model.device)\n",
    "        en_batch_hs = model(input_ids=en_id, attention_mask=en_am).hidden_states[1:]\n",
    "        fr_id = batch[\"fr_id\"].to(model.device)\n",
    "        fr_am = batch[\"fr_am\"].to(model.device)\n",
    "        fr_batch_hs = model(input_ids=fr_id, attention_mask=fr_am).hidden_states[1:]\n",
    "\n",
    "        get_embeds = lambda batch_hs, a_m: (batch_hs * a_m[..., None]).sum(axis=1) / a_m.sum(axis=-1)[..., None]\n",
    "        \n",
    "        # zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = 0\n",
    "        for en_hs, fr_hs in zip(en_batch_hs, fr_batch_hs):\n",
    "            en_embeds = get_embeds(en_hs, en_am)\n",
    "            fr_embeds = get_embeds(fr_hs, fr_am)\n",
    "            loss += loss_fn(en_embeds, fr_embeds)\n",
    "        \n",
    "        # calculate loss and accuracy\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_num += 1\n",
    "        if batch_num > 100 and debug:\n",
    "            break\n",
    "\n",
    "    train_loss /= BS * batch_num\n",
    "    valid_acc = eval(model, dls, lang, validation_split)\n",
    "    print(f'TRANSLATE {lang}: {train_loss} (val {valid_acc})')\n",
    "    return (train_loss, valid_acc)\n",
    "\n",
    "def train_translation(model, dls, dl_tr, lang, train_split, validation_split, num_epochs=2, need_tr=True, device='mps', debug=False):\n",
    "    # put model on mps device\n",
    "    model.to(device)\n",
    "    \n",
    "    # get needful data slice\n",
    "    dl_sentiment = dls[lang][train_split]\n",
    "    dl_translation = dl_tr[lang]\n",
    "\n",
    "    # define our optimizer and loss function\n",
    "    learning_rate_bert = 1e-6\n",
    "    learning_rate_classifier = 2e-5\n",
    "\n",
    "    # Set up parameter groups for different parts of the model\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\"params\": model.distilbert.parameters(), \"lr\": learning_rate_bert},\n",
    "        {\"params\": model.classifier.parameters(), \"lr\": learning_rate_classifier},\n",
    "    ]\n",
    "    optimizer = torch.optim.AdamW(optimizer_grouped_parameters)\n",
    "\n",
    "    collected_data = list()\n",
    "    for epoch in range(num_epochs):\n",
    "        # train loops\n",
    "        tr_res = epoch_translation(model, dls, dl_translation, lang, validation_split, optimizer, debug=debug)\n",
    "        collected_data.append(tr_res)\n",
    "\n",
    "        s_res = epoch_sentiment(model, dls, dl_sentiment, lang, validation_split, optimizer, 1000, debug=debug)\n",
    "        collected_data.append(s_res)\n",
    "\n",
    "    return collected_data\n",
    "\n",
    "def train_sentiment(model, dls, dl_tr, lang, train_split, validation_split, num_epochs=2, need_tr=True, device='mps', debug=False):\n",
    "    # put model on mps device\n",
    "    model.to(device)\n",
    "    \n",
    "    dl_sentiment = dls[lang][train_split]\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    collected_data = list()\n",
    "    for epoch in range(num_epochs):\n",
    "        # train loop\n",
    "        s_res = epoch_sentiment(model, dls, dl_sentiment, lang, validation_split, optimizer, debug=debug)\n",
    "        collected_data.append(s_res)\n",
    "\n",
    "    return collected_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b043ab8",
   "metadata": {
    "cellId": "3wabuxl4ehb1v2wpj5vfav"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "def assert_use_grad(model):          \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'clas' in name:\n",
    "            assert param.requires_grad\n",
    "        else:\n",
    "            assert param.requires_grad\n",
    "    print(f'model is ok (use_grad)')\n",
    "\n",
    "def assert_no_grad(model):       \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'clas' in name:\n",
    "            assert param.requires_grad\n",
    "        else:\n",
    "            assert not param.requires_grad\n",
    "    print(f'model is ok (no_grad)')\n",
    "\n",
    "def use_grad(model):\n",
    "    for lang in lang_list:\n",
    "        for param in model.base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "    assert_use_grad(model)\n",
    "\n",
    "def no_grad(model):\n",
    "    for lang in lang_list:\n",
    "        for param in model.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    assert_no_grad(model)\n",
    "\n",
    "def training_pipeline(lang, epochs=2, debug=False):\n",
    "    for lang in [lang]:\n",
    "        for i in range(epochs):\n",
    "            use_grad(models[lang])\n",
    "            cd_1 = train_translation(models[lang], dataloader, dataloaders_tr, lang, 'train', 'validation',\n",
    "                                     num_epochs=(3 if debug else 5), need_tr=True, device=device, debug=debug)\n",
    "            print(f'{i}: ', cd_1)\n",
    "\n",
    "            no_grad(models[lang])\n",
    "            cd_2 = train_sentiment(models[lang], dataloader, dataloaders_tr, lang, 'train', 'validation', \n",
    "                                   num_epochs=(1 if debug else 2), need_tr=True, device=device, debug=debug)    \n",
    "            print(f'{i}: ', cd_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "56af4ff8",
   "metadata": {
    "cellId": "v91uw7blqwkjgov5efvsq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is ok (use_grad)\n",
      "\teval fr: 0.821\n",
      "TRANSLATE fr: 0.004487292901013453 (val 0.821)\n",
      "\teval fr: 0.82975\n",
      "train fr: 0.8165625 (val 0.82975)\n",
      "\teval fr: 0.68975\n",
      "TRANSLATE fr: 0.004004931234118372 (val 0.68975)\n",
      "\teval fr: 0.8315\n",
      "train fr: 0.8246875 (val 0.8315)\n",
      "\teval fr: 0.838\n",
      "TRANSLATE fr: 0.00397068147529101 (val 0.838)\n",
      "\teval fr: 0.844\n",
      "train fr: 0.8359375 (val 0.844)\n",
      "0:  [(0.004487292901013453, 0.821), (0.8165625, 0.82975), (0.004004931234118372, 0.68975), (0.8246875, 0.8315), (0.00397068147529101, 0.838), (0.8359375, 0.844)]\n",
      "model is ok (no_grad)\n",
      "\teval fr: 0.8435\n",
      "train fr: 0.8376865671641791 (val 0.8435)\n",
      "0:  [(0.8376865671641791, 0.8435)]\n",
      "model is ok (use_grad)\n",
      "\teval fr: 0.8285\n",
      "TRANSLATE fr: 0.003365031314442063 (val 0.8285)\n",
      "\teval fr: 0.8445\n",
      "train fr: 0.814375 (val 0.8445)\n",
      "\teval fr: 0.83575\n",
      "TRANSLATE fr: 0.003034878704272727 (val 0.83575)\n",
      "\teval fr: 0.84875\n",
      "train fr: 0.8253125 (val 0.84875)\n",
      "\teval fr: 0.837\n",
      "TRANSLATE fr: 0.0030063006515144417 (val 0.837)\n",
      "\teval fr: 0.852\n",
      "train fr: 0.839375 (val 0.852)\n",
      "1:  [(0.003365031314442063, 0.8285), (0.814375, 0.8445), (0.003034878704272727, 0.83575), (0.8253125, 0.84875), (0.0030063006515144417, 0.837), (0.839375, 0.852)]\n",
      "model is ok (no_grad)\n",
      "\teval fr: 0.85375\n",
      "train fr: 0.8535447761194029 (val 0.85375)\n",
      "1:  [(0.8535447761194029, 0.85375)]\n",
      "model is ok (use_grad)\n",
      "\teval de: 0.71375\n",
      "TRANSLATE de: 0.012945874907666504 (val 0.71375)\n",
      "\teval de: 0.76825\n",
      "train de: 0.7378125 (val 0.76825)\n",
      "\teval de: 0.76575\n",
      "TRANSLATE de: 0.009755971915282236 (val 0.76575)\n",
      "\teval de: 0.779\n",
      "train de: 0.7578125 (val 0.779)\n",
      "\teval de: 0.7695\n",
      "TRANSLATE de: 0.008448034418875924 (val 0.7695)\n",
      "\teval de: 0.78325\n",
      "train de: 0.7703125 (val 0.78325)\n",
      "0:  [(0.012945874907666504, 0.71375), (0.7378125, 0.76825), (0.009755971915282236, 0.76575), (0.7578125, 0.779), (0.008448034418875924, 0.7695), (0.7703125, 0.78325)]\n",
      "model is ok (no_grad)\n",
      "\teval de: 0.786\n",
      "train de: 0.7776741293532339 (val 0.786)\n",
      "0:  [(0.7776741293532339, 0.786)]\n",
      "model is ok (use_grad)\n",
      "\teval de: 0.77675\n",
      "TRANSLATE de: 0.006571958039767376 (val 0.77675)\n",
      "\teval de: 0.79\n",
      "train de: 0.76125 (val 0.79)\n",
      "\teval de: 0.741\n",
      "TRANSLATE de: 0.00551503860751296 (val 0.741)\n",
      "\teval de: 0.744\n",
      "train de: 0.775 (val 0.744)\n",
      "\teval de: 0.72725\n",
      "TRANSLATE de: 0.00513746746179491 (val 0.72725)\n",
      "\teval de: 0.7895\n",
      "train de: 0.7809375 (val 0.7895)\n",
      "1:  [(0.006571958039767376, 0.77675), (0.76125, 0.79), (0.00551503860751296, 0.741), (0.775, 0.744), (0.00513746746179491, 0.72725), (0.7809375, 0.7895)]\n",
      "model is ok (no_grad)\n",
      "\teval de: 0.791\n",
      "train de: 0.7907338308457711 (val 0.791)\n",
      "1:  [(0.7907338308457711, 0.791)]\n",
      "model is ok (use_grad)\n",
      "\teval es: 0.792\n",
      "TRANSLATE es: 0.012071576559602623 (val 0.792)\n",
      "\teval es: 0.8055\n",
      "train es: 0.7825 (val 0.8055)\n",
      "\teval es: 0.795\n",
      "TRANSLATE es: 0.008966510700486085 (val 0.795)\n",
      "\teval es: 0.80575\n",
      "train es: 0.7990625 (val 0.80575)\n",
      "\teval es: 0.80625\n",
      "TRANSLATE es: 0.007914636602237969 (val 0.80625)\n",
      "\teval es: 0.812\n",
      "train es: 0.8059375 (val 0.812)\n",
      "0:  [(0.012071576559602623, 0.792), (0.7825, 0.8055), (0.008966510700486085, 0.795), (0.7990625, 0.80575), (0.007914636602237969, 0.80625), (0.8059375, 0.812)]\n",
      "model is ok (no_grad)\n",
      "\teval es: 0.81425\n",
      "train es: 0.8125 (val 0.81425)\n",
      "0:  [(0.8125, 0.81425)]\n",
      "model is ok (use_grad)\n",
      "\teval es: 0.80675\n",
      "TRANSLATE es: 0.006150663092658662 (val 0.80675)\n",
      "\teval es: 0.81825\n",
      "train es: 0.8003125 (val 0.81825)\n",
      "\teval es: 0.7615\n",
      "TRANSLATE es: 0.005223168115509619 (val 0.7615)\n",
      "\teval es: 0.82575\n",
      "train es: 0.819375 (val 0.82575)\n",
      "\teval es: 0.81275\n",
      "TRANSLATE es: 0.00492933579250285 (val 0.81275)\n",
      "\teval es: 0.821\n",
      "train es: 0.824375 (val 0.821)\n",
      "1:  [(0.006150663092658662, 0.80675), (0.8003125, 0.81825), (0.005223168115509619, 0.7615), (0.819375, 0.82575), (0.00492933579250285, 0.81275), (0.824375, 0.821)]\n",
      "model is ok (no_grad)\n",
      "\teval es: 0.82975\n",
      "train es: 0.8174751243781094 (val 0.82975)\n",
      "1:  [(0.8174751243781094, 0.82975)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 100/3125 [00:08<04:12, 11.99it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.04it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:11, 12.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.04it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:17, 11.75it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.46it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.04it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "  4%|▍         | 200/5000 [00:41<16:30,  4.85it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.46it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:12, 12.00it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.46it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:13, 11.93it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.46it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:18, 11.70it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.42it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "  4%|▍         | 200/5000 [00:41<16:42,  4.79it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:19, 11.66it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.41it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:18, 11.68it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.42it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:17, 11.73it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "  4%|▍         | 200/5000 [00:41<16:39,  4.80it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:11, 12.05it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.50it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:12, 12.00it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:19, 11.67it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.42it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "  4%|▍         | 200/5000 [00:41<16:39,  4.80it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:19, 11.64it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.42it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:18, 11.71it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:16, 11.81it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "  4%|▍         | 200/5000 [00:41<16:37,  4.81it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:19, 11.65it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.43it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:19, 11.64it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.45it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "  3%|▎         | 100/3125 [00:08<04:17, 11.73it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.44it/s]\n",
      "100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "  4%|▍         | 200/5000 [00:41<16:41,  4.79it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "for lang in lang_list:\n",
    "    if lang != 'en':\n",
    "        training_pipeline(lang, epochs=2, debug=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1616a355",
   "metadata": {
    "cellId": "mu0icirfayllefn0xqz8wn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is ok (use_grad)\n",
      "\teval fr: 0.5\n",
      "TRANSLATE fr: 0.0018882102750334888 (val 0.5)\n",
      "\teval fr: 0.81175\n",
      "train fr: 0.73271875 (val 0.81175)\n",
      "\teval fr: 0.79775\n",
      "TRANSLATE fr: 0.0003935722163692117 (val 0.79775)\n",
      "\teval fr: 0.83725\n",
      "train fr: 0.815625 (val 0.83725)\n",
      "\teval fr: 0.8285\n",
      "TRANSLATE fr: 0.0003471001837681979 (val 0.8285)\n",
      "\teval fr: 0.852\n",
      "train fr: 0.83534375 (val 0.852)\n",
      "\teval fr: 0.83725\n",
      "TRANSLATE fr: 0.0003154149005515501 (val 0.83725)\n",
      "\teval fr: 0.859\n",
      "train fr: 0.84553125 (val 0.859)\n",
      "\teval fr: 0.8375\n",
      "TRANSLATE fr: 0.00029923732010181994 (val 0.8375)\n",
      "\teval fr: 0.8645\n",
      "train fr: 0.8541875 (val 0.8645)\n",
      "0:  [(0.0018882102750334888, 0.5), (0.73271875, 0.81175), (0.0003935722163692117, 0.79775), (0.815625, 0.83725), (0.0003471001837681979, 0.8285), (0.83534375, 0.852), (0.0003154149005515501, 0.83725), (0.84553125, 0.859), (0.00029923732010181994, 0.8375), (0.8541875, 0.8645)]\n",
      "model is ok (no_grad)\n",
      "\teval fr: 0.869\n",
      "train fr: 0.8637 (val 0.869)\n",
      "\teval fr: 0.8685\n",
      "train fr: 0.86400625 (val 0.8685)\n",
      "0:  [(0.8637, 0.869), (0.86400625, 0.8685)]\n",
      "model is ok (use_grad)\n",
      "\teval fr: 0.52725\n",
      "TRANSLATE fr: 0.00011642454574699513 (val 0.52725)\n",
      "\teval fr: 0.84125\n",
      "train fr: 0.82446875 (val 0.84125)\n",
      "\teval fr: 0.8395\n",
      "TRANSLATE fr: 8.365937790600582e-05 (val 0.8395)\n",
      "\teval fr: 0.85775\n",
      "train fr: 0.85334375 (val 0.85775)\n",
      "\teval fr: 0.8575\n",
      "TRANSLATE fr: 8.995946059701964e-05 (val 0.8575)\n",
      "\teval fr: 0.8595\n",
      "train fr: 0.86565625 (val 0.8595)\n",
      "\teval fr: 0.8565\n",
      "TRANSLATE fr: 9.459715751698241e-05 (val 0.8565)\n",
      "\teval fr: 0.8785\n",
      "train fr: 0.87040625 (val 0.8785)\n",
      "\teval fr: 0.868\n",
      "TRANSLATE fr: 9.6362382681109e-05 (val 0.868)\n",
      "\teval fr: 0.8745\n",
      "train fr: 0.873625 (val 0.8745)\n",
      "1:  [(0.00011642454574699513, 0.52725), (0.82446875, 0.84125), (8.365937790600582e-05, 0.8395), (0.85334375, 0.85775), (8.995946059701964e-05, 0.8575), (0.86565625, 0.8595), (9.459715751698241e-05, 0.8565), (0.87040625, 0.8785), (9.6362382681109e-05, 0.868), (0.873625, 0.8745)]\n",
      "model is ok (no_grad)\n",
      "\teval fr: 0.883\n",
      "train fr: 0.8800125 (val 0.883)\n",
      "\teval fr: 0.88025\n",
      "train fr: 0.8804 (val 0.88025)\n",
      "1:  [(0.8800125, 0.883), (0.8804, 0.88025)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [17:15<00:00,  4.83it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.45it/s]\n",
      "100%|██████████| 5000/5000 [17:09<00:00,  4.85it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "training_pipeline('fr', epochs=2, debug=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bf8a5501",
   "metadata": {
    "cellId": "o6xzzdex53mxxai77p0lal"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is ok (use_grad)\n",
      "\teval de: 0.49975\n",
      "TRANSLATE de: 0.0022574793294258414 (val 0.49975)\n",
      "\teval de: 0.7875\n",
      "train de: 0.70653125 (val 0.7875)\n",
      "\teval de: 0.779\n",
      "TRANSLATE de: 0.0003889742057584226 (val 0.779)\n",
      "\teval de: 0.80975\n",
      "train de: 0.79275 (val 0.80975)\n",
      "\teval de: 0.75325\n",
      "TRANSLATE de: 0.00032856806331314146 (val 0.75325)\n",
      "\teval de: 0.8245\n",
      "train de: 0.8146875 (val 0.8245)\n",
      "\teval de: 0.8025\n",
      "TRANSLATE de: 0.00029973368672188373 (val 0.8025)\n",
      "\teval de: 0.831\n",
      "train de: 0.82315625 (val 0.831)\n",
      "\teval de: 0.79175\n",
      "TRANSLATE de: 0.0002834173326473683 (val 0.79175)\n",
      "\teval de: 0.84525\n",
      "train de: 0.8360625 (val 0.84525)\n",
      "0:  [(0.0022574793294258414, 0.49975), (0.70653125, 0.7875), (0.0003889742057584226, 0.779), (0.79275, 0.80975), (0.00032856806331314146, 0.75325), (0.8146875, 0.8245), (0.00029973368672188373, 0.8025), (0.82315625, 0.831), (0.0002834173326473683, 0.79175), (0.8360625, 0.84525)]\n",
      "model is ok (no_grad)\n",
      "\teval de: 0.84775\n",
      "train de: 0.845225 (val 0.84775)\n",
      "\teval de: 0.84975\n",
      "train de: 0.84408125 (val 0.84975)\n",
      "0:  [(0.845225, 0.84775), (0.84408125, 0.84975)]\n",
      "model is ok (use_grad)\n",
      "\teval de: 0.5045\n",
      "TRANSLATE de: 0.00011253345345612615 (val 0.5045)\n",
      "\teval de: 0.8365\n",
      "train de: 0.8073125 (val 0.8365)\n",
      "\teval de: 0.79375\n",
      "TRANSLATE de: 8.539405119139702e-05 (val 0.79375)\n",
      "\teval de: 0.84\n",
      "train de: 0.83746875 (val 0.84)\n",
      "\teval de: 0.80425\n",
      "TRANSLATE de: 8.939714096253738e-05 (val 0.80425)\n",
      "\teval de: 0.854\n",
      "train de: 0.846125 (val 0.854)\n",
      "\teval de: 0.791\n",
      "TRANSLATE de: 9.107805734034628e-05 (val 0.791)\n",
      "\teval de: 0.857\n",
      "train de: 0.8538125 (val 0.857)\n",
      "\teval de: 0.8505\n",
      "TRANSLATE de: 9.17828250862658e-05 (val 0.8505)\n",
      "\teval de: 0.86425\n",
      "train de: 0.854125 (val 0.86425)\n",
      "1:  [(0.00011253345345612615, 0.5045), (0.8073125, 0.8365), (8.539405119139702e-05, 0.79375), (0.83746875, 0.84), (8.939714096253738e-05, 0.80425), (0.846125, 0.854), (9.107805734034628e-05, 0.791), (0.8538125, 0.857), (9.17828250862658e-05, 0.8505), (0.854125, 0.86425)]\n",
      "model is ok (no_grad)\n",
      "\teval de: 0.8665\n",
      "train de: 0.86341875 (val 0.8665)\n",
      "\teval de: 0.86625\n",
      "train de: 0.86333125 (val 0.86625)\n",
      "1:  [(0.86341875, 0.8665), (0.86333125, 0.86625)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:56<00:00,  4.92it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.53it/s]\n",
      "100%|██████████| 5000/5000 [16:57<00:00,  4.92it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "training_pipeline('de', epochs=2, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ee734887",
   "metadata": {
    "cellId": "de841ueg3a9j978gj7721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is ok (use_grad)\n",
      "\teval es: 0.50375\n",
      "TRANSLATE es: 0.0020478245209529997 (val 0.50375)\n",
      "\teval es: 0.792\n",
      "train es: 0.72803125 (val 0.792)\n",
      "\teval es: 0.67525\n",
      "TRANSLATE es: 0.00039636514275334775 (val 0.67525)\n",
      "\teval es: 0.8215\n",
      "train es: 0.80309375 (val 0.8215)\n",
      "\teval es: 0.65775\n",
      "TRANSLATE es: 0.0003367180655570701 (val 0.65775)\n",
      "\teval es: 0.83375\n",
      "train es: 0.82740625 (val 0.83375)\n",
      "\teval es: 0.65825\n",
      "TRANSLATE es: 0.0003086267004720867 (val 0.65825)\n",
      "\teval es: 0.8475\n",
      "train es: 0.83746875 (val 0.8475)\n",
      "\teval es: 0.6525\n",
      "TRANSLATE es: 0.0002886756160762161 (val 0.6525)\n",
      "\teval es: 0.85475\n",
      "train es: 0.84875 (val 0.85475)\n",
      "0:  [(0.0020478245209529997, 0.50375), (0.72803125, 0.792), (0.00039636514275334775, 0.67525), (0.80309375, 0.8215), (0.0003367180655570701, 0.65775), (0.82740625, 0.83375), (0.0003086267004720867, 0.65825), (0.83746875, 0.8475), (0.0002886756160762161, 0.6525), (0.84875, 0.85475)]\n",
      "model is ok (no_grad)\n",
      "\teval es: 0.85575\n",
      "train es: 0.8551 (val 0.85575)\n",
      "\teval es: 0.854\n",
      "train es: 0.85646875 (val 0.854)\n",
      "0:  [(0.8551, 0.85575), (0.85646875, 0.854)]\n",
      "model is ok (use_grad)\n",
      "\teval es: 0.50125\n",
      "TRANSLATE es: 9.374256368842908e-05 (val 0.50125)\n",
      "\teval es: 0.84175\n",
      "train es: 0.8179375 (val 0.84175)\n",
      "\teval es: 0.66275\n",
      "TRANSLATE es: 7.064763293485157e-05 (val 0.66275)\n",
      "\teval es: 0.85575\n",
      "train es: 0.84775 (val 0.85575)\n",
      "\teval es: 0.671\n",
      "TRANSLATE es: 7.182986674597487e-05 (val 0.671)\n",
      "\teval es: 0.8635\n",
      "train es: 0.8515 (val 0.8635)\n",
      "\teval es: 0.6625\n",
      "TRANSLATE es: 7.422110663261264e-05 (val 0.6625)\n",
      "\teval es: 0.858\n",
      "train es: 0.85546875 (val 0.858)\n",
      "\teval es: 0.70825\n",
      "TRANSLATE es: 7.805774723296054e-05 (val 0.70825)\n",
      "\teval es: 0.8465\n",
      "train es: 0.863 (val 0.8465)\n",
      "1:  [(9.374256368842908e-05, 0.50125), (0.8179375, 0.84175), (7.064763293485157e-05, 0.66275), (0.84775, 0.85575), (7.182986674597487e-05, 0.671), (0.8515, 0.8635), (7.422110663261264e-05, 0.6625), (0.85546875, 0.858), (7.805774723296054e-05, 0.70825), (0.863, 0.8465)]\n",
      "model is ok (no_grad)\n",
      "\teval es: 0.86925\n",
      "train es: 0.87061875 (val 0.86925)\n",
      "\teval es: 0.87325\n",
      "train es: 0.87044375 (val 0.87325)\n",
      "1:  [(0.87061875, 0.86925), (0.87044375, 0.87325)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [16:57<00:00,  4.92it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.54it/s]\n",
      "100%|██████████| 5000/5000 [16:57<00:00,  4.91it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.52it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "training_pipeline('es', epochs=2, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "325395c1",
   "metadata": {
    "cellId": "qa2fgao5ukfkk0bc29ikdh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:22<00:00,  5.51it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.52it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\teval en: 0.87675\n",
      "\teval fr: 0.87575\n",
      "\teval de: 0.864\n",
      "\teval es: 0.87675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_89482028_041a_11ee_9843_d00d101ca97drow0_col0 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_89482028_041a_11ee_9843_d00d101ca97drow1_col0 {\n",
       "            background-color:  #128912;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_89482028_041a_11ee_9843_d00d101ca97drow2_col0 {\n",
       "            background-color:  #ebf3eb;\n",
       "            color:  #000000;\n",
       "        }    #T_89482028_041a_11ee_9843_d00d101ca97drow3_col0 {\n",
       "            background-color:  #008000;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_89482028_041a_11ee_9843_d00d101ca97d\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >full</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_89482028_041a_11ee_9843_d00d101ca97dlevel0_row0\" class=\"row_heading level0 row0\" >en</th>\n",
       "                        <td id=\"T_89482028_041a_11ee_9843_d00d101ca97drow0_col0\" class=\"data row0 col0\" >0.87675</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89482028_041a_11ee_9843_d00d101ca97dlevel0_row1\" class=\"row_heading level0 row1\" >fr</th>\n",
       "                        <td id=\"T_89482028_041a_11ee_9843_d00d101ca97drow1_col0\" class=\"data row1 col0\" >0.87575</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89482028_041a_11ee_9843_d00d101ca97dlevel0_row2\" class=\"row_heading level0 row2\" >de</th>\n",
       "                        <td id=\"T_89482028_041a_11ee_9843_d00d101ca97drow2_col0\" class=\"data row2 col0\" >0.864</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_89482028_041a_11ee_9843_d00d101ca97dlevel0_row3\" class=\"row_heading level0 row3\" >es</th>\n",
       "                        <td id=\"T_89482028_041a_11ee_9843_d00d101ca97drow3_col0\" class=\"data row3 col0\" >0.87675</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa2c079e340>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "\n",
    "eval_res = pd.DataFrame(data = np.zeros((4, 1)), columns = ['full'], index=lang_list)\n",
    "\n",
    "# for lang in lang_list:\n",
    "for lang in lang_list:\n",
    "    test_res = eval(models[lang], dataloader, lang, 'test')\n",
    "    eval_res.at[lang, 'full'] = test_res\n",
    "\n",
    "nice_df(eval_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d223d45",
   "metadata": {
    "cellId": "ne0bgfq7y4bwoojyp8xggh",
    "execution_id": "bc8e8a99-a2de-4297-a0f6-411996f59207"
   },
   "source": [
    "## Saving Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b833b9",
   "metadata": {
    "cellId": "7t3cw9ugylr4ywwhg6j7k"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "for lang in lang_list:\n",
    "    if lang != 'en':\n",
    "        models[lang].save_pretrained(f'models/ft_best_{lang}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "88271500-c35a-4736-b1ad-bf53657add83",
  "notebookPath": "full_pipeline.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
