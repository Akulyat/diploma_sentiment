{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def nice_df(df, axis=None, reverse=False, **kwargs):\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True, reverse=reverse)\n",
    "    return df.style.background_gradient(cmap=cm, axis=axis, **kwargs)\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, load_from_disk\n",
    "lang_list = ['en', 'fr', 'de', 'es']\n",
    "data = {\n",
    "    lang: load_from_disk(f'handle_amazon/amazon_ok_tr_{lang}')\n",
    "    for lang in lang_list\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Pipeline (small, monolingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24942684918642044\n"
     ]
    }
   ],
   "source": [
    "pipeline_classifier = pipeline(\"sentiment-analysis\", truncation='only_first', device=device)\n",
    "print(pipeline_classifier.model.num_parameters() * 4 / 2**30)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeroshot Pipeline (big, multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.517475139349699\n"
     ]
    }
   ],
   "source": [
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", truncation='only_first', device=device)\n",
    "print(zeroshot_classifier.model.num_parameters() * 4 / 2**30)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(ds, model, need_labels = True):\n",
    "    if need_labels:\n",
    "        res = model(\n",
    "            ds['review_body'],\n",
    "            candidate_labels=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "    else:\n",
    "        res = model(ds['review_body'])\n",
    "\n",
    "    if need_labels:\n",
    "        pred = [x['labels'][0] == \"POSITIVE\" for x in res]\n",
    "    else:\n",
    "        pred = [x['label'] == \"POSITIVE\" for x in res]\n",
    "\n",
    "    pred = torch.tensor(pred).int()\n",
    "    labels = torch.tensor(ds['bin_label'])\n",
    "    return torch.mean((pred == labels).float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en  0.8962500095367432 0.8972499966621399\n",
      "fr  0.8090000152587891 0.8212500214576721\n",
      "de  0.8054999709129333 0.7994999885559082\n",
      "es  0.8690000176429749 0.8582500219345093\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_17b23_row0_col0 {\n",
       "  background-color: #028102;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17b23_row0_col1 {\n",
       "  background-color: #008000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17b23_row1_col0 {\n",
       "  background-color: #d4e8d4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17b23_row1_col1 {\n",
       "  background-color: #b7dab7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17b23_row2_col0 {\n",
       "  background-color: #ddecdd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17b23_row2_col1 {\n",
       "  background-color: #ebf3eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17b23_row3_col0 {\n",
       "  background-color: #43a143;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17b23_row3_col1 {\n",
       "  background-color: #5eae5e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_17b23\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_17b23_level0_col0\" class=\"col_heading level0 col0\" >sent_test</th>\n",
       "      <th id=\"T_17b23_level0_col1\" class=\"col_heading level0 col1\" >sent_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_17b23_level0_row0\" class=\"row_heading level0 row0\" >en</th>\n",
       "      <td id=\"T_17b23_row0_col0\" class=\"data row0 col0\" >0.896250</td>\n",
       "      <td id=\"T_17b23_row0_col1\" class=\"data row0 col1\" >0.897250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17b23_level0_row1\" class=\"row_heading level0 row1\" >fr</th>\n",
       "      <td id=\"T_17b23_row1_col0\" class=\"data row1 col0\" >0.809000</td>\n",
       "      <td id=\"T_17b23_row1_col1\" class=\"data row1 col1\" >0.821250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17b23_level0_row2\" class=\"row_heading level0 row2\" >de</th>\n",
       "      <td id=\"T_17b23_row2_col0\" class=\"data row2 col0\" >0.805500</td>\n",
       "      <td id=\"T_17b23_row2_col1\" class=\"data row2 col1\" >0.799500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17b23_level0_row3\" class=\"row_heading level0 row3\" >es</th>\n",
       "      <td id=\"T_17b23_row3_col0\" class=\"data row3 col0\" >0.869000</td>\n",
       "      <td id=\"T_17b23_row3_col1\" class=\"data row3 col1\" >0.858250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2b398a4d0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeroshot_res = pd.DataFrame(data = np.zeros((4, 2)), columns = ['sent_test', 'sent_val'], index=['en', 'fr', 'de', 'es'])\n",
    "for lang in lang_list:\n",
    "    ds_test = data[lang]['test']\n",
    "    ds_val = data[lang]['validation']\n",
    "    test_lres = run(ds_test, zeroshot_classifier, need_labels=True).item()\n",
    "    val_lres = run(ds_val, zeroshot_classifier, need_labels=True).item()\n",
    "\n",
    "    zeroshot_res.at[lang, 'sent_test'] = test_lres\n",
    "    zeroshot_res.at[lang, 'sent_val'] = val_lres\n",
    "    print(f\"{lang} \", test_lres, val_lres)\n",
    "\n",
    "\n",
    "nice_df(zeroshot_res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en  0.8510000109672546 0.846750020980835\n",
      "fr  0.6292499899864197 0.6187499761581421\n",
      "de  0.5120000243186951 0.5117499828338623\n",
      "es  0.6157500147819519 0.6127499938011169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_17d73_row0_col0 {\n",
       "  background-color: #008000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d73_row0_col1 {\n",
       "  background-color: #038103;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_17d73_row1_col0 {\n",
       "  background-color: #9acb9a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d73_row1_col1 {\n",
       "  background-color: #a1cfa1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d73_row2_col0, #T_17d73_row2_col1 {\n",
       "  background-color: #ebf3eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d73_row3_col0 {\n",
       "  background-color: #a3d0a3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_17d73_row3_col1 {\n",
       "  background-color: #a5d1a5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_17d73\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_17d73_level0_col0\" class=\"col_heading level0 col0\" >sent_test</th>\n",
       "      <th id=\"T_17d73_level0_col1\" class=\"col_heading level0 col1\" >sent_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_17d73_level0_row0\" class=\"row_heading level0 row0\" >en</th>\n",
       "      <td id=\"T_17d73_row0_col0\" class=\"data row0 col0\" >0.851000</td>\n",
       "      <td id=\"T_17d73_row0_col1\" class=\"data row0 col1\" >0.846750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d73_level0_row1\" class=\"row_heading level0 row1\" >fr</th>\n",
       "      <td id=\"T_17d73_row1_col0\" class=\"data row1 col0\" >0.629250</td>\n",
       "      <td id=\"T_17d73_row1_col1\" class=\"data row1 col1\" >0.618750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d73_level0_row2\" class=\"row_heading level0 row2\" >de</th>\n",
       "      <td id=\"T_17d73_row2_col0\" class=\"data row2 col0\" >0.512000</td>\n",
       "      <td id=\"T_17d73_row2_col1\" class=\"data row2 col1\" >0.511750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17d73_level0_row3\" class=\"row_heading level0 row3\" >es</th>\n",
       "      <td id=\"T_17d73_row3_col0\" class=\"data row3 col0\" >0.615750</td>\n",
       "      <td id=\"T_17d73_row3_col1\" class=\"data row3 col1\" >0.612750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14dd40190>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_res = pd.DataFrame(data = np.zeros((4, 2)), columns = ['sent_test', 'sent_val'], index=['en', 'fr', 'de', 'es'])\n",
    "for lang in lang_list:\n",
    "    ds_test = data[lang]['test']\n",
    "    ds_val = data[lang]['validation']\n",
    "    test_lres = run(ds_test, pipeline_classifier, need_labels=False).item()\n",
    "    val_lres = run(ds_val, pipeline_classifier, need_labels=False).item()\n",
    "\n",
    "    sentiment_res.at[lang, 'sent_test'] = test_lres\n",
    "    sentiment_res.at[lang, 'sent_val'] = val_lres\n",
    "    print(f\"{lang} \", test_lres, val_lres)\n",
    "\n",
    "nice_df(sentiment_res)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubbish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(137) tensor(512)\n",
      "512\n",
      "tensor(46) tensor(400)\n",
      "400\n",
      "tensor(18) tensor(448)\n",
      "448\n",
      "tensor(34) tensor(368)\n",
      "368\n"
     ]
    }
   ],
   "source": [
    "for lang in lang_list:\n",
    "    print(data[lang]['train'][0]['attention_mask'].sum(), (data[lang]['train'][0]['attention_mask'] >= 0).sum())\n",
    "    # len(data['en']['train']['review_body'][0].split()), data['en']['train']['review_body'][0]\n",
    "    input_ids = data[lang]['train'][0]['input_ids']\n",
    "    print(len(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [304] at entry 0 and [384] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[160], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m lang \u001b[39min\u001b[39;00m lang_list:\n\u001b[1;32m      2\u001b[0m     train_dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(data[lang][\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m], batch_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m      5\u001b[0m         \u001b[39mif\u001b[39;00m batch[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m512\u001b[39m:\n\u001b[1;32m      6\u001b[0m             \u001b[39mprint\u001b[39m(lang, batch[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/HSE/Diploma/venvDiploma/lib/python3.11/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Desktop/HSE/Diploma/venvDiploma/lib/python3.11/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/HSE/Diploma/venvDiploma/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/Desktop/HSE/Diploma/venvDiploma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:264\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    204\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/Desktop/HSE/Diploma/venvDiploma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;49;00m key \u001b[39min\u001b[39;49;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/Desktop/HSE/Diploma/venvDiploma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/Desktop/HSE/Diploma/venvDiploma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    121\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/Desktop/HSE/Diploma/venvDiploma/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_typed_storage()\u001b[39m.\u001b[39m_new_shared(numel, device\u001b[39m=\u001b[39melem\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39mnew(storage)\u001b[39m.\u001b[39mresize_(\u001b[39mlen\u001b[39m(batch), \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(elem\u001b[39m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mstack(batch, \u001b[39m0\u001b[39;49m, out\u001b[39m=\u001b[39;49mout)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [304] at entry 0 and [384] at entry 1"
     ]
    }
   ],
   "source": [
    "for lang in lang_list:\n",
    "    train_dataloader = torch.utils.data.DataLoader(data[lang]['train'], batch_size=8, shuffle=True)\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        if batch['input_ids'].shape[-1] != 512:\n",
    "            print(lang, batch['input_ids'].shape[-1])\n",
    "            break\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_09ec1_row0_col0, #T_09ec1_row0_col1, #T_09ec1_row0_col3, #T_09ec1_row0_col4, #T_09ec1_row1_col0, #T_09ec1_row1_col1, #T_09ec1_row1_col3, #T_09ec1_row1_col4, #T_09ec1_row2_col0, #T_09ec1_row2_col1, #T_09ec1_row2_col3, #T_09ec1_row2_col4, #T_09ec1_row3_col0, #T_09ec1_row3_col1, #T_09ec1_row3_col3, #T_09ec1_row3_col4 {\n",
       "  background-color: #008000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_09ec1_row0_col2, #T_09ec1_row1_col2, #T_09ec1_row2_col2, #T_09ec1_row3_col2 {\n",
       "  background-color: #ebf3eb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_09ec1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_09ec1_level0_col0\" class=\"col_heading level0 col0\" >1</th>\n",
       "      <th id=\"T_09ec1_level0_col1\" class=\"col_heading level0 col1\" >2</th>\n",
       "      <th id=\"T_09ec1_level0_col2\" class=\"col_heading level0 col2\" >3</th>\n",
       "      <th id=\"T_09ec1_level0_col3\" class=\"col_heading level0 col3\" >4</th>\n",
       "      <th id=\"T_09ec1_level0_col4\" class=\"col_heading level0 col4\" >5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_09ec1_level0_row0\" class=\"row_heading level0 row0\" >en</th>\n",
       "      <td id=\"T_09ec1_row0_col0\" class=\"data row0 col0\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row0_col1\" class=\"data row0 col1\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row0_col2\" class=\"data row0 col2\" >0.000000</td>\n",
       "      <td id=\"T_09ec1_row0_col3\" class=\"data row0 col3\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row0_col4\" class=\"data row0 col4\" >1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09ec1_level0_row1\" class=\"row_heading level0 row1\" >fr</th>\n",
       "      <td id=\"T_09ec1_row1_col0\" class=\"data row1 col0\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row1_col1\" class=\"data row1 col1\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
       "      <td id=\"T_09ec1_row1_col3\" class=\"data row1 col3\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row1_col4\" class=\"data row1 col4\" >1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09ec1_level0_row2\" class=\"row_heading level0 row2\" >de</th>\n",
       "      <td id=\"T_09ec1_row2_col0\" class=\"data row2 col0\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row2_col1\" class=\"data row2 col1\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
       "      <td id=\"T_09ec1_row2_col3\" class=\"data row2 col3\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row2_col4\" class=\"data row2 col4\" >1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_09ec1_level0_row3\" class=\"row_heading level0 row3\" >es</th>\n",
       "      <td id=\"T_09ec1_row3_col0\" class=\"data row3 col0\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row3_col1\" class=\"data row3 col1\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row3_col2\" class=\"data row3 col2\" >0.000000</td>\n",
       "      <td id=\"T_09ec1_row3_col3\" class=\"data row3 col3\" >1000.000000</td>\n",
       "      <td id=\"T_09ec1_row3_col4\" class=\"data row3 col4\" >1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14d00af90>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "star_dist = pd.DataFrame(data = np.zeros((4, 5)), columns = np.arange(1, 6), index=['en', 'fr', 'de', 'es'])\n",
    "\n",
    "for lang in lang_list:\n",
    "    ds_test = load_from_disk(f'handle_amazon/amazon_{lang}')['test']\n",
    "    for i in range(1, 6):\n",
    "        lres = (ds_test['stars'] == i).int().sum().item()\n",
    "        star_dist.at[lang, i] = lres\n",
    "nice_df(star_dist) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id, output_hidden_states=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 32])\n",
      "torch.Size([6, 768])\n",
      "tensor([0])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m     data \u001b[39m=\u001b[39m tokenizer(X_train_german[\u001b[39m5\u001b[39m], padding\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39minput_ids\n\u001b[1;32m     25\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39margmax(model(data)\u001b[39m.\u001b[39mlogits, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mprint\u001b[39m([x[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m pipeline_classifier(X_train_german)])\n\u001b[1;32m     28\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m     29\u001b[0m     \u001b[39mprint\u001b[39m([x[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m zeroshot_classifier(X_train_german, candidate_labels\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mNEGATIVE\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPOSITIVE\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mNEUTRAL\u001b[39m\u001b[39m\"\u001b[39m])])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipeline_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_german = [\n",
    "    \"Mit keinem guten Ergebnis\",\n",
    "    \"Das war unfair\",\n",
    "    \"Das ist gar nicht mal so gut\",\n",
    "    \"nicht so schlecht wie erwartet\",\n",
    "    \"Das war gut!\",\n",
    "    \"Sie fahrt ein grunes Auto\",\n",
    "]\n",
    "X_train_spain = [\n",
    "    \"Sin buen resultado.\",\n",
    "    \"Eso fue injusto.\",\n",
    "    \"Eso ni siquiera es tan bueno.\",\n",
    "    \"no tan malo como se esperaba.\",\n",
    "    \"¡Eso estuvo bueno!\",\n",
    "    \"Conduce un coche verde.\",\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = torch.tensor(tokenizer(X_train_german, padding=True, pad_to_multiple_of=32).input_ids)\n",
    "    print(data.shape)\n",
    "    print(model(data).hidden_states[-1].mean(dim=1).shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = tokenizer(X_train_german[5], padding=True, return_tensors='pt').input_ids\n",
    "    print(torch.argmax(model(data).logits, axis=1))\n",
    "    print([x['label'] for x in pipeline_classifier(X_train_german)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    print([x['labels'][0] for x in zeroshot_classifier(X_train_german, candidate_labels=[\"NEGATIVE\", \"POSITIVE\", \"NEUTRAL\"])])\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = tokenizer(X_train_german[5], padding=True, return_tensors='pt').input_ids\n",
    "    print(torch.argmax(model(data).logits, axis=1))\n",
    "    print([x['label'] for x in pipeline_classifier(X_train_spain)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    print([x['labels'][0] for x in zeroshot_classifier(X_train_spain, candidate_labels=[\"NEGATIVE\", \"POSITIVE\", \"NEUTRAL\"])])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDiploma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
