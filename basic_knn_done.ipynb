{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "m0kl2jsvx7aokidqsvcwj",
    "execution_id": "375b099e-b300-4163-b2a3-021340aa0856"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cellId": "w5gmgna06vaeg6qvr22rq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def nice_df(df, axis=None, reverse=False, **kwargs):\n",
    "    cm = sns.light_palette(\"green\", as_cmap=True, reverse=reverse)\n",
    "    return df.style.background_gradient(cmap=cm, axis=axis, **kwargs)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zthh55dge8ociknehhhv7",
    "execution_id": "f6c4788b-88f3-42ac-81fb-ffec19d10c84"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cellId": "fhxaw4hj3argapjv3v9qk9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from datasets import concatenate_datasets, load_from_disk\n",
    "\n",
    "BS = 32\n",
    "lang_list = ['en', 'fr', 'de', 'es']\n",
    "split_list = ['train', 'validation', 'test']\n",
    "\n",
    "\n",
    "data = {\n",
    "    lang: load_from_disk(f'handle_amazon/amazon_ok_tr_{lang}')\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n",
    "dataloader = {\n",
    "    lang: {\n",
    "        split: DataLoader(data[lang][split], batch_size=BS, shuffle=(split == 'train'))\n",
    "        for split in split_list\n",
    "    }\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "vxdfo50ztfupzhb47rz4",
    "execution_id": "e60627ec-97fd-4180-93eb-822aa43cdb0f"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cellId": "vflgv7ku078rrjdlqmbnck"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce9a7f40d4043a3905629f6b9182f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f0c525fa3f428c8bc54df8f15033b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3267,  0.0176,  0.1214,  ...,  0.0836, -0.0200, -0.1360],\n",
      "        [ 0.1976,  0.1497,  0.1829,  ...,  0.0148,  0.0260, -0.0101],\n",
      "        [ 0.1492,  0.0464,  0.1645,  ..., -0.0861, -0.0884,  0.0062],\n",
      "        ...,\n",
      "        [ 0.1911,  0.1054, -0.0288,  ..., -0.0056,  0.0567, -0.1306],\n",
      "        [ 0.1369,  0.0744,  0.1030,  ...,  0.0234, -0.1261, -0.0686],\n",
      "        [ 0.1460,  0.2451,  0.0183,  ...,  0.1160, -0.0157, -0.1809]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.1394, -0.1306],\n",
      "        [ 0.1361, -0.1175],\n",
      "        [ 0.1149, -0.0921],\n",
      "        [ 0.0970, -0.1148],\n",
      "        [ 0.0732, -0.0850],\n",
      "        [ 0.0743, -0.0979],\n",
      "        [ 0.1071, -0.1082],\n",
      "        [ 0.1054, -0.1558],\n",
      "        [ 0.0569, -0.0800],\n",
      "        [ 0.1023, -0.0974],\n",
      "        [ 0.1134, -0.0870],\n",
      "        [ 0.1020, -0.0854],\n",
      "        [ 0.1184, -0.0616],\n",
      "        [ 0.1070, -0.0862],\n",
      "        [ 0.1203, -0.1260],\n",
      "        [ 0.0716, -0.0795],\n",
      "        [ 0.1182, -0.1321],\n",
      "        [ 0.0721, -0.1105],\n",
      "        [ 0.1005, -0.1020],\n",
      "        [ 0.0903, -0.0749],\n",
      "        [ 0.0690, -0.0845],\n",
      "        [ 0.1406, -0.1174],\n",
      "        [ 0.1370, -0.0936],\n",
      "        [ 0.1389, -0.1001],\n",
      "        [ 0.0759, -0.1091],\n",
      "        [ 0.1362, -0.0735],\n",
      "        [ 0.0956, -0.1455],\n",
      "        [ 0.1069, -0.0800],\n",
      "        [ 0.0803, -0.0999],\n",
      "        [ 0.1413, -0.1022],\n",
      "        [ 0.1204, -0.0559],\n",
      "        [ 0.0951, -0.0991]], device='cuda:0')\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
    "\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id, output_hidden_states=True)\n",
    "model.to(device)\n",
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader['en']['test']:\n",
    "        i_d = batch[\"input_ids\"].to(device)\n",
    "        a_m = batch[\"attention_mask\"].to(device)\n",
    "        batch_hs = model(\n",
    "                input_ids=i_d,\n",
    "                attention_mask=a_m,\n",
    "            ).hidden_states[-1].mean(dim=1)    \n",
    "        print(batch_hs)\n",
    "\n",
    "        logits = model(\n",
    "                input_ids=i_d,\n",
    "                attention_mask=a_m,\n",
    "            ).logits    \n",
    "        print(logits)\n",
    "\n",
    "        print(torch.argmax(\n",
    "            model(\n",
    "                input_ids=i_d,\n",
    "                attention_mask=a_m,\n",
    "            ).logits,\n",
    "            axis=-1\n",
    "        ))\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cellId": "iwalxf859tra10k6smalo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_classifier.weight torch.Size([768, 768]) True\n",
      "pre_classifier.bias torch.Size([768]) True\n",
      "classifier.weight torch.Size([2, 768]) True\n",
      "classifier.bias torch.Size([2]) True\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for name, param in model.named_parameters():\n",
    "    if 'clas' in name:\n",
    "        print(name, param.shape, param.requires_grad)\n",
    "    else:\n",
    "        assert not param.requires_grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "6u1g4xifa06uok6eg1n5jh",
    "execution_id": "b176b167-ecfc-41c5-ab60-96e56e5482bb"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cellId": "cemaz4x45xbbpl4epufjtp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# translators = {\n",
    "#     lang: pipeline(\"translation\", model=f\"Helsinki-NLP/opus-mt-{lang}-en\", batch_size=8, max_length=150)\n",
    "#     for lang in ['fr', 'de', 'es']\n",
    "# }\n",
    "\n",
    "translators_back = {\n",
    "    lang: pipeline(\"translation\", model=f\"Helsinki-NLP/opus-mt-en-{lang}\", max_length=150)\n",
    "    for lang in ['fr', 'de', 'es']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellId": "oxouxb1blpzjf9slwrys"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenization(example):\n",
    "    return tokenizer(example, truncation=True, padding=True, pad_to_multiple_of=512)\n",
    "\n",
    "extreme_words = [\n",
    "    'negative',\n",
    "    'terrible',\n",
    "    'horrible',\n",
    "    'awful',\n",
    "    'dreadful',\n",
    "    'lousy',\n",
    "    'abysmal',\n",
    "    'dismal',\n",
    "    'unpleasant',\n",
    "    'repulsive',\n",
    "    'completely devastated',\n",
    "    'an utter disaster',\n",
    "    'can\\'t stand it anymore',\n",
    "    'a total nightmare',\n",
    "    'feels completely hopeless',\n",
    "    'at my breaking point',\n",
    "    'the worst thing ever',\n",
    "    'can\\'t take it anymore',\n",
    "    'I\\'m completely miserable',\n",
    "    'I\\'m absolutely crushed',\n",
    "\n",
    "    'positive',\n",
    "    'wonderful',\n",
    "    'excellent',\n",
    "    'fantastic',\n",
    "    'amazing',\n",
    "    'great',\n",
    "    'superb',\n",
    "    'outstanding',\n",
    "    'perfect',\n",
    "    'fabulous',\n",
    "    'absolutely fantastic',\n",
    "    'feels over the moon',\n",
    "    'a dream coming true',\n",
    "    'I\\'m so thrilled',\n",
    "    'amazing news',\n",
    "    'can\\'t believe how wonderful this is',\n",
    "    'the best thing ever',\n",
    "    'I\\'m ecstatic about this',\n",
    "    'feels on top of the world',\n",
    "    'I\\'m overjoyed',\n",
    "]\n",
    "\n",
    "extreme_dict = {\n",
    "    'en': extreme_words\n",
    "}\n",
    "\n",
    "for lang in ['fr', 'de', 'es']:\n",
    "    extreme_dict[lang] = [x['translation_text'] for x in translators_back[lang](extreme_words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cellId": "ut4lrf6ev8ljb13okosc2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 768])\n",
      "torch.Size([40, 768])\n",
      "torch.Size([40, 768])\n",
      "torch.Size([40, 768])\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "extreme_data_dict = {\n",
    "    lang: [tokenization(word) for word in extreme_dict[lang]]\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n",
    "i_d = {\n",
    "    lang: torch.tensor([word[\"input_ids\"] for word in extreme_data_dict[lang]]).to(device)\n",
    "    for lang in lang_list\n",
    "}\n",
    "a_m = {\n",
    "    lang: torch.tensor([word[\"attention_mask\"] for word in extreme_data_dict[lang]]).to(device)\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n",
    "batch_hs = {\n",
    "    lang: model(\n",
    "        input_ids=i_d[lang],\n",
    "        attention_mask=a_m[lang],\n",
    "    ).hidden_states[-1]  \n",
    "    for lang in lang_list\n",
    "}\n",
    "\n",
    "masked_hs = {\n",
    "    lang: batch_hs[lang] * a_m[lang][..., None]\n",
    "    for lang in lang_list\n",
    "}\n",
    "extreme_embeds = {\n",
    "    lang: masked_hs[lang].sum(axis=1) / a_m[lang].sum(axis=-1)[..., None]\n",
    "    for lang in lang_list\n",
    "}\n",
    "\n",
    "\n",
    "for lang in lang_list:\n",
    "    print(extreme_embeds[lang].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "6zw8harn3or47e4mgk64s1",
    "execution_id": "6c0153e2-160c-49b3-81ff-bf4ae7973f02"
   },
   "source": [
    "An example of extreme embeds to be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cellId": "trhk0ujkbgaa4j4ni9q1k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "l_lang = 'fr'\n",
    "ex_ex = extreme_embeds[l_lang] @ extreme_embeds[l_lang].T\n",
    "\n",
    "num_nn = 5\n",
    "values, indices = torch.topk(ex_ex, k=num_nn, dim=1)\n",
    "num_extremes = extreme_embeds[l_lang].shape[0] // 2\n",
    "((indices >= num_extremes).sum(dim=-1) > num_nn / 2).int()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "4ypcd142729qi7m5yenbkn",
    "execution_id": "80b0af0f-cca5-4da1-8bdf-83c93be1371f"
   },
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cellId": "p6u6sasudb7tw0ki1xs1v"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "def run_with_head(dl, model):\n",
    "    acc = 0\n",
    "    for batch in tqdm(dl):\n",
    "        i_d = batch[\"input_ids\"].to(model.device)\n",
    "        a_m = batch[\"attention_mask\"].to(model.device)\n",
    "        logits = model(\n",
    "                input_ids=i_d,\n",
    "                attention_mask=a_m,\n",
    "            ).logits.to('cpu')\n",
    "\n",
    "        preds = torch.argmax(logits, axis=-1)\n",
    "        labels = batch['bin_label']\n",
    "        acc += (preds == labels).float().mean()\n",
    "    acc /= len(dl)\n",
    "    return acc\n",
    "\n",
    "def run_knn_handmade(dl, model, extreme_embeds, num_nn=5):\n",
    "    acc = 0\n",
    "    for batch in tqdm(dl):\n",
    "        i_d = batch[\"input_ids\"].to(model.device)\n",
    "        a_m = batch[\"attention_mask\"].to(model.device)\n",
    "\n",
    "        batch_hs = model(\n",
    "                input_ids=i_d,\n",
    "                attention_mask=a_m,\n",
    "            ).hidden_states[-1]\n",
    "\n",
    "        masked_hs = batch_hs * a_m[..., None]\n",
    "        embeds = masked_hs.sum(axis=1) / a_m.sum(axis=-1)[..., None]\n",
    "\n",
    "        corr = embeds @ extreme_embeds.T\n",
    "\n",
    "        _, indices = torch.topk(corr, k=num_nn, dim=1)\n",
    "        num_extremes = extreme_embeds.shape[0] // 2\n",
    "        preds = ((indices >= num_extremes).sum(dim=-1) > num_nn / 2).int().to('cpu')\n",
    "\n",
    "        labels = batch['bin_label']\n",
    "        acc += (preds == labels).float().mean()\n",
    "    acc /= len(dl)\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cellId": "z8k870wauyk37dkmdpwu2m"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# run_with_head(dataloader['en']['test'], model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cellId": "1h2w62vm1ntxf0enwqos5s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOK at en\n",
      "knn(1) = 0.5882499814033508\n",
      "knn(3) = 0.6462500095367432\n",
      "knn(5) = 0.625249981880188\n",
      "knn(7) = 0.5364999771118164\n",
      "knn(9) = 0.5195000171661377\n",
      "knn(11) = 0.5122500061988831\n",
      "knn(13) = 0.5147500038146973\n",
      "knn(15) = 0.5172500014305115\n",
      "knn(17) = 0.6112499833106995\n",
      "knn(19) = 0.5917500257492065\n",
      "knn(21) = 0.5214999914169312\n",
      "knn(23) = 0.5217499732971191\n",
      "knn(25) = 0.5230000019073486\n",
      "knn(27) = 0.5295000076293945\n",
      "\n",
      "LOOK at fr\n",
      "knn(1) = 0.47850000858306885\n",
      "knn(3) = 0.48750001192092896\n",
      "knn(5) = 0.49950000643730164\n",
      "knn(7) = 0.5007500052452087\n",
      "knn(9) = 0.5005000233650208\n",
      "knn(11) = 0.49950000643730164\n",
      "knn(13) = 0.5019999742507935\n",
      "knn(15) = 0.503000020980835\n",
      "knn(17) = 0.5044999718666077\n",
      "knn(19) = 0.5082499980926514\n",
      "knn(21) = 0.5082499980926514\n",
      "knn(23) = 0.5047500133514404\n",
      "knn(25) = 0.5027499794960022\n",
      "knn(27) = 0.5027499794960022\n",
      "\n",
      "LOOK at de\n",
      "knn(1) = 0.4987500011920929\n",
      "knn(3) = 0.5049999952316284\n",
      "knn(5) = 0.5199999809265137\n",
      "knn(7) = 0.5017499923706055\n",
      "knn(9) = 0.5027499794960022\n",
      "knn(11) = 0.49524998664855957\n",
      "knn(13) = 0.5042499899864197\n",
      "knn(15) = 0.5270000100135803\n",
      "knn(17) = 0.5264999866485596\n",
      "knn(19) = 0.5517500042915344\n",
      "knn(21) = 0.5412499904632568\n",
      "knn(23) = 0.5222499966621399\n",
      "knn(25) = 0.5372499823570251\n",
      "knn(27) = 0.5582500100135803\n",
      "\n",
      "LOOK at es\n",
      "knn(1) = 0.5115000009536743\n",
      "knn(3) = 0.5817499756813049\n",
      "knn(5) = 0.6002500057220459\n",
      "knn(7) = 0.5992500185966492\n",
      "knn(9) = 0.5477499961853027\n",
      "knn(11) = 0.5122500061988831\n",
      "knn(13) = 0.5074999928474426\n",
      "knn(15) = 0.5077499747276306\n",
      "knn(17) = 0.500249981880188\n",
      "knn(19) = 0.47450000047683716\n",
      "knn(21) = 0.4652499854564667\n",
      "knn(23) = 0.476500004529953\n",
      "knn(25) = 0.4729999899864197\n",
      "knn(27) = 0.5072500109672546\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:22<00:00,  5.50it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.50it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.50it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.50it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.42it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.46it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n",
      "100%|██████████| 125/125 [00:23<00:00,  5.43it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.48it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.47it/s]\n",
      "100%|██████████| 125/125 [00:22<00:00,  5.49it/s]\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "for lang in lang_list:\n",
    "    ans_to_print = f\"LOOK at {lang}\\n\"\n",
    "\n",
    "    for num_nn in range(1, 29, 2):\n",
    "        res = run_knn_handmade(dataloader['en']['test'], model, extreme_embeds[lang], num_nn)\n",
    "        ans_to_print += f'knn({num_nn}) = {res}\\n'\n",
    "        # print(num_nn, \"done\")\n",
    "\n",
    "    print(ans_to_print)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "5cvhpz4dsdkuvvl2alb6o"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "71193c2d-f0f7-458e-b6ed-20cdfd8a42d0",
  "notebookPath": "basic_knn.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
